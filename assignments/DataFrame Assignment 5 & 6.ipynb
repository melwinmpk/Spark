{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"learning\").master(\"local\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *****PySpark DF Question*****\n",
    "## 1) Input:\n",
    "## Col1\n",
    "## Saif=A\n",
    "## Ram=B\n",
    "## Ram=B\n",
    "## Mitali=C\n",
    "## Mitali=C\n",
    "## Mitali=C\n",
    "## \n",
    "## Output: \n",
    "## Key\tValue\n",
    "## Saif\t1\n",
    "## Ram\t2\n",
    "## Mitali \t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Col: string (nullable = true)\n",
      "\n",
      "+--------+\n",
      "|     Col|\n",
      "+--------+\n",
      "|  Saif=A|\n",
      "|   Ram=B|\n",
      "|   Ram=B|\n",
      "|Mitali=C|\n",
      "|Mitali=C|\n",
      "|Mitali=C|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = ['Saif=A','Ram=B','Ram=B','Mitali=C','Mitali=C','Mitali=C']\n",
    "\n",
    "df = spark.createDataFrame(data,'string').toDF('Col')\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  Name|value|\n",
      "+------+-----+\n",
      "|  Saif|    1|\n",
      "|   Ram|    2|\n",
      "|Mitali|    3|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col('*'), split(df['Col'],'=').getItem(0).alias('Name'),\n",
    "                    split(df['Col'],'=').getItem(1).alias('Section'))\\\n",
    "                    .groupby('Name').count().orderBy('count')\\\n",
    "                    .withColumnRenamed('count','value')\\\n",
    "                    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *****PySpark DF Question*****\n",
    "## 1) You are provided with sales.txt file at location /home/saif/LFS/cca175/. \n",
    "## \n",
    "## Output: \n",
    "## Find the employee count & cost to company for each group consisting of dept, cadre, and \n",
    "## state. Compress the output using gzip compression & write the data of costToCompany \n",
    "## greater than 50000 to location /user/saif/HFS/CCA_175/Output in a single file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dept: string (nullable = true)\n",
      " |-- cadre: string (nullable = true)\n",
      " |-- costToCompany: integer (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n",
      "+-----+-------+-------------+-----+\n",
      "| dept|  cadre|costToCompany|state|\n",
      "+-----+-------+-------------+-----+\n",
      "|Sales|Trainee|        12000|   UK|\n",
      "|Sales|   Lead|        32000|  AUS|\n",
      "|Sales|   Lead|        32000|   NY|\n",
      "|Sales|   Lead|        32000|  IND|\n",
      "|Sales|   Lead|        32000|  AUS|\n",
      "+-----+-------+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df = spark.read.format(\"csv\")\\\n",
    "                     .option('header','True')\\\n",
    "                     .option('delimiter',',')\\\n",
    "                     .option('inferSchema','True')\\\n",
    "                     .load('file:///home/saif/LFS/datasets/sales.txt')\n",
    "\n",
    "sales_df.printSchema()\n",
    "sales_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+\n",
      "|     dept|sum(costToCompany)|\n",
      "+---------+------------------+\n",
      "|    Sales|            236000|\n",
      "|       HR|             58000|\n",
      "|Marketing|             36000|\n",
      "+---------+------------------+\n",
      "\n",
      "+---------+------------------+\n",
      "|    cadre|sum(costToCompany)|\n",
      "+---------+------------------+\n",
      "|Associate|             36000|\n",
      "|     Lead|            224000|\n",
      "|  Trainee|             12000|\n",
      "|  Manager|             58000|\n",
      "+---------+------------------+\n",
      "\n",
      "+-----+------------------+\n",
      "|state|sum(costToCompany)|\n",
      "+-----+------------------+\n",
      "|  AUS|             64000|\n",
      "|   NY|             96000|\n",
      "|   UK|             12000|\n",
      "|  IND|            158000|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.groupby('dept').sum().show()\n",
    "sales_df.groupby('cadre').sum().show()\n",
    "sales_df.groupby('state').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----+-----------------+\n",
      "|     dept|    cadre|state|CostToCompany_Sum|\n",
      "+---------+---------+-----+-----------------+\n",
      "|Marketing|Associate|  IND|            36000|\n",
      "|    Sales|  Trainee|   UK|            12000|\n",
      "|    Sales|     Lead|   NY|            96000|\n",
      "|    Sales|     Lead|  IND|            64000|\n",
      "|       HR|  Manager|  IND|            58000|\n",
      "|    Sales|     Lead|  AUS|            64000|\n",
      "+---------+---------+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df.select(col('dept'),col('cadre'),col('state'),col('costToCompany'))\\\n",
    "        .groupby(['dept','cadre','state'])\\\n",
    "        .sum('costToCompany').withColumnRenamed('sum(costToCompany)','CostToCompany_Sum')\\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-------------+-----+\n",
      "|dept|  cadre|costToCompany|state|\n",
      "+----+-------+-------------+-----+\n",
      "|  HR|Manager|        58000|  IND|\n",
      "+----+-------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Compress the output using gzip compression & write the data of costToCompany  \n",
    "greater than 50000 to location /user/saif/HFS/CCA_175/Output in a single file.\n",
    "'''\n",
    "df2 = sales_df.filter(col(\"costToCompany\") > 50000)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.write.format('csv')\\\n",
    "         .mode('overwrite')\\\n",
    "        .option(\"codec\", \"org.apache.hadoop.io.compress.GzipCodec\")\\\n",
    "        .save('hdfs://localhost:9000/user/saif/HFS/Output/df_op/30thdec_gzip_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
