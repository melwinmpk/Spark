{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM 2**: Fetch total orders made by married male customers belonging to Central America occupied in a clerical job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('learning').master('local')\\\n",
    "                    .config('spark.jars','/home/saif/LFS/jars/spark-xml_2.12-0.5.0.jar')\\\n",
    "                    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "# Note for the 1st Method config option is not required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1\n",
    "## Reading excel file Using Pandas then converting it to Data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_pd_df = pd.read_excel('file:///home/saif/LFS/datasets/datasets_pavan/sales/customers.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerKey</th>\n",
       "      <th>Prefix</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>BirthDate</th>\n",
       "      <th>MaritalStatus</th>\n",
       "      <th>Gender</th>\n",
       "      <th>AnnualIncome</th>\n",
       "      <th>TotalChildren</th>\n",
       "      <th>EducationLevel</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>HomeOwner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11000.0</td>\n",
       "      <td>MR.</td>\n",
       "      <td>JON</td>\n",
       "      <td>YANG</td>\n",
       "      <td>1966-04-08</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11001.0</td>\n",
       "      <td>MR.</td>\n",
       "      <td>EUGENE</td>\n",
       "      <td>HUANG</td>\n",
       "      <td>1965-05-14</td>\n",
       "      <td>S</td>\n",
       "      <td>M</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11002.0</td>\n",
       "      <td>MR.</td>\n",
       "      <td>RUBEN</td>\n",
       "      <td>TORRES</td>\n",
       "      <td>1965-08-12</td>\n",
       "      <td>M</td>\n",
       "      <td>M</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11003.0</td>\n",
       "      <td>MS.</td>\n",
       "      <td>CHRISTY</td>\n",
       "      <td>ZHU</td>\n",
       "      <td>1968-02-15</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11004.0</td>\n",
       "      <td>MRS.</td>\n",
       "      <td>ELIZABETH</td>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>1968-08-08</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerKey Prefix  FirstName LastName  BirthDate MaritalStatus Gender  \\\n",
       "0      11000.0    MR.        JON     YANG 1966-04-08             M      M   \n",
       "1      11001.0    MR.     EUGENE    HUANG 1965-05-14             S      M   \n",
       "2      11002.0    MR.      RUBEN   TORRES 1965-08-12             M      M   \n",
       "3      11003.0    MS.    CHRISTY      ZHU 1968-02-15             S      F   \n",
       "4      11004.0   MRS.  ELIZABETH  JOHNSON 1968-08-08             S      F   \n",
       "\n",
       "   AnnualIncome  TotalChildren EducationLevel    Occupation HomeOwner  \n",
       "0       90000.0            2.0      Bachelors  Professional         Y  \n",
       "1       60000.0            3.0      Bachelors  Professional         N  \n",
       "2       60000.0            3.0      Bachelors  Professional         Y  \n",
       "3       70000.0            0.0      Bachelors  Professional         N  \n",
       "4       80000.0            5.0      Bachelors  Professional         Y  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_pd_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0        Professional\n",
       "1        Professional\n",
       "2        Professional\n",
       "3        Professional\n",
       "4        Professional\n",
       "             ...     \n",
       "18143        Clerical\n",
       "18144        Clerical\n",
       "18145        Clerical\n",
       "18146        Clerical\n",
       "18147        Clerical\n",
       "Name: Occupation, Length: 18148, dtype: object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_pd_df['Occupation'].value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomerKey              float64\n",
       "Prefix                    object\n",
       "FirstName                 object\n",
       "LastName                  object\n",
       "BirthDate         datetime64[ns]\n",
       "MaritalStatus             object\n",
       "Gender                    object\n",
       "AnnualIncome             float64\n",
       "TotalChildren            float64\n",
       "EducationLevel            object\n",
       "Occupation                object\n",
       "HomeOwner                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_pd_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StringType, StructField,IntegerType,FloatType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = StructType([\n",
    "            StructField('CustomerKey',FloatType(),True ),\n",
    "            StructField('Prefix',StringType(),True ),\n",
    "            StructField('FirstName',StringType(),True ),\n",
    "            StructField('LastName',StringType(),True ),\n",
    "            StructField('BirthDate',DateType(),True ),\n",
    "            StructField('MaritalStatus',StringType(),True ),\n",
    "            StructField('Gender',StringType(),True ),\n",
    "            StructField('AnnualIncome',FloatType(),True ),\n",
    "            StructField('TotalChildren',FloatType(),True ),\n",
    "            StructField('EducationLevel',StringType(),True ),\n",
    "            StructField('Occupation',StringType(),True ),\n",
    "            StructField('HomeOwner',StringType(),True )  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerKey: float (nullable = true)\n",
      " |-- Prefix: string (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- BirthDate: date (nullable = true)\n",
      " |-- MaritalStatus: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- AnnualIncome: float (nullable = true)\n",
      " |-- TotalChildren: float (nullable = true)\n",
      " |-- EducationLevel: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- HomeOwner: string (nullable = true)\n",
      "\n",
      "+-----------+------+---------+--------+----------+-------------+------+------------+-------------+--------------+------------+---------+\n",
      "|CustomerKey|Prefix|FirstName|LastName| BirthDate|MaritalStatus|Gender|AnnualIncome|TotalChildren|EducationLevel|  Occupation|HomeOwner|\n",
      "+-----------+------+---------+--------+----------+-------------+------+------------+-------------+--------------+------------+---------+\n",
      "|    11000.0|   MR.|      JON|    YANG|1966-04-08|            M|     M|     90000.0|          2.0|     Bachelors|Professional|        Y|\n",
      "|    11001.0|   MR.|   EUGENE|   HUANG|1965-05-14|            S|     M|     60000.0|          3.0|     Bachelors|Professional|        N|\n",
      "|    11002.0|   MR.|    RUBEN|  TORRES|1965-08-12|            M|     M|     60000.0|          3.0|     Bachelors|Professional|        Y|\n",
      "|    11003.0|   MS.|  CHRISTY|     ZHU|1968-02-15|            S|     F|     70000.0|          0.0|     Bachelors|Professional|        N|\n",
      "|    11004.0|  MRS.|ELIZABETH| JOHNSON|1968-08-08|            S|     F|     80000.0|          5.0|     Bachelors|Professional|        Y|\n",
      "+-----------+------+---------+--------+----------+-------------+------+------------+-------------+--------------+------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df = spark.createDataFrame(customer_pd_df,data_schema)\n",
    "customer_df.printSchema()\n",
    "customer_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2 Using a liberary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_schema = StructType([\n",
    "            StructField('CustomerKey',FloatType(),True ),\n",
    "            StructField('Prefix',StringType(),True ),\n",
    "            StructField('FirstName',StringType(),True ),\n",
    "            StructField('LastName',StringType(),True ),\n",
    "            StructField('BirthDate',DateType(),True ),\n",
    "            StructField('MaritalStatus',StringType(),True ),\n",
    "            StructField('Gender',StringType(),True ),\n",
    "            StructField('AnnualIncome',FloatType(),True ),\n",
    "            StructField('TotalChildren',FloatType(),True ),\n",
    "            StructField('EducationLevel',StringType(),True ),\n",
    "            StructField('Occupation',StringType(),True ),\n",
    "            StructField('HomeOwner',StringType(),True )  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CustomerKey: float (nullable = true)\n",
      " |-- Prefix: string (nullable = true)\n",
      " |-- FirstName: string (nullable = true)\n",
      " |-- LastName: string (nullable = true)\n",
      " |-- BirthDate: date (nullable = true)\n",
      " |-- MaritalStatus: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- AnnualIncome: float (nullable = true)\n",
      " |-- TotalChildren: float (nullable = true)\n",
      " |-- EducationLevel: string (nullable = true)\n",
      " |-- Occupation: string (nullable = true)\n",
      " |-- HomeOwner: string (nullable = true)\n",
      "\n",
      "+-----------+------+---------+--------+---------+-------------+------+------------+-------------+--------------+----------+---------+\n",
      "|CustomerKey|Prefix|FirstName|LastName|BirthDate|MaritalStatus|Gender|AnnualIncome|TotalChildren|EducationLevel|Occupation|HomeOwner|\n",
      "+-----------+------+---------+--------+---------+-------------+------+------------+-------------+--------------+----------+---------+\n",
      "+-----------+------+---------+--------+---------+-------------+------+------------+-------------+--------------+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df=spark.read.format(\"com.databricks.spark.xml\") \\\n",
    "          .option('header', 'True') \\\n",
    "          .option('inferSchema','True')\\\n",
    "          .schema(data_schema) \\\n",
    "          .load('file:///home/saif/LFS/datasets/datasets_pavan/sales/customers.xlsx')\n",
    "\n",
    "customer_df.printSchema()\n",
    "customer_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ReturnDate: string (nullable = true)\n",
      " |-- TerritoryKey: integer (nullable = true)\n",
      " |-- ProductKey: integer (nullable = true)\n",
      " |-- ReturnQuantity: integer (nullable = true)\n",
      "\n",
      "+----------+------------+----------+--------------+\n",
      "|ReturnDate|TerritoryKey|ProductKey|ReturnQuantity|\n",
      "+----------+------------+----------+--------------+\n",
      "| 1/18/2015|           9|       312|             1|\n",
      "| 1/18/2015|          10|       310|             1|\n",
      "| 1/21/2015|           8|       346|             1|\n",
      "| 1/22/2015|           4|       311|             1|\n",
      "|  2/2/2015|           6|       312|             1|\n",
      "+----------+------------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders_returns_df = spark.read.format('csv')\\\n",
    "          .option('header', 'True') \\\n",
    "          .option('inferSchema', 'True') \\\n",
    "          .load('file:///home/saif/LFS/datasets/datasets_pavan/sales/order_returns.csv')\n",
    "orders_returns_df.printSchema()\n",
    "orders_returns_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SalesTerritoryKey: integer (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Continent: string (nullable = true)\n",
      "\n",
      "+-----------------+---------+-------------+-------------+\n",
      "|SalesTerritoryKey|   Region|      Country|    Continent|\n",
      "+-----------------+---------+-------------+-------------+\n",
      "|                1|Northwest|United States|North America|\n",
      "|                2|Northeast|United States|North America|\n",
      "|                3|  Central|United States|North America|\n",
      "|                4|Southwest|United States|North America|\n",
      "|                5|Southeast|United States|North America|\n",
      "+-----------------+---------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "territories_df = spark.read.format('csv')\\\n",
    "          .option('header', 'True') \\\n",
    "          .option('inferSchema', 'True') \\\n",
    "          .load('file:///home/saif/LFS/datasets/datasets_pavan/sales/territories.csv')\n",
    "territories_df.printSchema()\n",
    "territories_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|    Continent|\n",
      "+-------------+\n",
      "|       Europe|\n",
      "|North America|\n",
      "|      Pacific|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "territories_df.select(\"Continent\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|        Region|\n",
      "+--------------+\n",
      "|       Germany|\n",
      "|        France|\n",
      "|     Northwest|\n",
      "|     Southeast|\n",
      "|       Central|\n",
      "|        Canada|\n",
      "|     Southwest|\n",
      "|     Australia|\n",
      "|United Kingdom|\n",
      "|     Northeast|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "territories_df.select(\"Region\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- OrderDate: string (nullable = true)\n",
      " |-- StockDate: string (nullable = true)\n",
      " |-- OrderNumber: string (nullable = true)\n",
      " |-- ProductKey: integer (nullable = true)\n",
      " |-- CustomerKey: integer (nullable = true)\n",
      " |-- TerritoryKey: integer (nullable = true)\n",
      " |-- OrderLineItem: integer (nullable = true)\n",
      " |-- OrderQuantity: integer (nullable = true)\n",
      "\n",
      "+----------+----------+-----------+----------+-----------+------------+-------------+-------------+\n",
      "| OrderDate| StockDate|OrderNumber|ProductKey|CustomerKey|TerritoryKey|OrderLineItem|OrderQuantity|\n",
      "+----------+----------+-----------+----------+-----------+------------+-------------+-------------+\n",
      "|01-01-2015| 9/21/2001|    SO45080|       332|      14657|           1|            1|            1|\n",
      "|01-01-2015|12-05-2001|    SO45079|       312|      29255|           4|            1|            1|\n",
      "|01-01-2015|10/29/2001|    SO45082|       350|      11455|           9|            1|            1|\n",
      "|01-01-2015|11/16/2001|    SO45081|       338|      26782|           6|            1|            1|\n",
      "|01-02-2015|12/15/2001|    SO45083|       312|      14947|          10|            1|            1|\n",
      "+----------+----------+-----------+----------+-----------+------------+-------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales_df = spark.read.format('csv')\\\n",
    "          .option('header', 'True') \\\n",
    "          .option('inferSchema', 'True') \\\n",
    "          .load('file:///home/saif/LFS/datasets/datasets_pavan/sales/sales.csv')\n",
    "sales_df.printSchema()\n",
    "sales_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(customer_df.where((col('MaritalStatus') == 'M') & (col('Gender') == 'M'))).join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = sales_df.join(customer_df, customer_df.CustomerKey == sales_df.CustomerKey, 'inner')\\\n",
    "        .join(territories_df, sales_df.TerritoryKey == territories_df.SalesTerritoryKey , 'inner')\\\n",
    "        .where( \n",
    "        (customer_df.MaritalStatus == 'M') & (customer_df.Gender == 'M') & \n",
    "        (customer_df.Occupation == 'Clerical')  \n",
    "        & (territories_df.Country == 'United States')\n",
    "        #& (territories_df.Region == 'Central')\n",
    "        )\\\n",
    "        .select(customer_df.MaritalStatus,customer_df.Gender,customer_df.Occupation,territories_df.Continent,\n",
    "               sales_df.OrderNumber)\n",
    "#         .groupby(sales_df.OrderNumber)\\\n",
    "#         .count(sales_df.OrderNumber)\\\n",
    "        \n",
    "# Melwin Please Note when I add the condition   (territories_df.Region == 'Central') I am getting empty data set  \n",
    "# as per the Question we need to add them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|OrderNumber|count|\n",
      "+-----------+-----+\n",
      "|    SO67006|    4|\n",
      "|    SO51242|    3|\n",
      "|    SO66963|    3|\n",
      "|    SO57642|    3|\n",
      "|    SO70660|    4|\n",
      "|    SO61289|    3|\n",
      "|    SO67984|    3|\n",
      "|    SO57440|    3|\n",
      "|    SO48526|    1|\n",
      "|    SO64113|    3|\n",
      "|    SO73559|    3|\n",
      "|    SO51552|    3|\n",
      "|    SO65630|    1|\n",
      "|    SO73465|    2|\n",
      "|    SO73377|    2|\n",
      "|    SO60533|    1|\n",
      "|    SO56391|    2|\n",
      "|    SO66219|    3|\n",
      "|    SO68973|    4|\n",
      "|    SO73152|    4|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_df.select(col('OrderNumber')).groupby('OrderNumber').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
