{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa22cab-6595-4b12-9e28-128d5aee43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24abf045-66df-421a-8d8d-6080b314f38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d8b50a-0e04-45b9-9567-06b42ae7e73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/07/22 01:23:16 WARN Utils: Your hostname, de24, resolves to a loopback address: 127.0.1.1; using 192.168.0.102 instead (on interface enp0s3)\n",
      "25/07/22 01:23:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/22 01:23:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.102:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>1251</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7e98d02d0200>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local[4]\").appName(\"1251\").getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6978c30e-8420-41c8-96eb-db2c51e02fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Table: Prices\n",
    "\n",
    "+---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| product_id    | int     |\n",
    "| start_date    | date    |\n",
    "| end_date      | date    |\n",
    "| price         | int     |\n",
    "+---------------+---------+\n",
    "(product_id, start_date, end_date) is the primary key (combination of columns with unique values) \n",
    "for this table.\n",
    "Each row of this table indicates the price of the product_id in the period from start_date to \n",
    "end_date.\n",
    "For each product_id there will be no two overlapping periods. That means there will be no two \n",
    "intersecting periods for the \n",
    "same product_id.\n",
    " \n",
    "\n",
    "Table: UnitsSold\n",
    "\n",
    "+---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| product_id    | int     |\n",
    "| purchase_date | date    |\n",
    "| units         | int     |\n",
    "+---------------+---------+\n",
    "This table may contain duplicate rows.\n",
    "Each row of this table indicates the date, units, and product_id of each product sold. \n",
    " \n",
    "\n",
    "Write a solution to find the average selling price for each product. average_price should be \n",
    "rounded to 2 decimal places.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Prices table:\n",
    "+------------+------------+------------+--------+\n",
    "| product_id | start_date | end_date   | price  |\n",
    "+------------+------------+------------+--------+\n",
    "| 1          | 2019-02-17 | 2019-02-28 | 5      |\n",
    "| 1          | 2019-03-01 | 2019-03-22 | 20     |\n",
    "| 2          | 2019-02-01 | 2019-02-20 | 15     |\n",
    "| 2          | 2019-02-21 | 2019-03-31 | 30     |\n",
    "+------------+------------+------------+--------+\n",
    "UnitsSold table:\n",
    "+------------+---------------+-------+\n",
    "| product_id | purchase_date | units |\n",
    "+------------+---------------+-------+\n",
    "| 1          | 2019-02-25    | 100   |\n",
    "| 1          | 2019-03-01    | 15    |\n",
    "| 2          | 2019-02-10    | 200   |\n",
    "| 2          | 2019-03-22    | 30    |\n",
    "+------------+---------------+-------+\n",
    "Output: \n",
    "+------------+---------------+\n",
    "| product_id | average_price |\n",
    "+------------+---------------+\n",
    "| 1          | 6.96          |\n",
    "| 2          | 16.96         |\n",
    "+------------+---------------+\n",
    "Explanation: \n",
    "Average selling price = Total Price of Product / Number of products sold.\n",
    "Average selling price for product 1 = ((100 * 5) + (15 * 20)) / 115 = 6.96\n",
    "Average selling price for product 2 = ((200 * 15) + (30 * 30)) / 230 = 16.96\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e5ebaa-23e1-4d55-9b3b-cf887390ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = [\n",
    "(1,'2019-02-17','2019-02-28',5 ),\n",
    "(1,'2019-03-01','2019-03-22',20),\n",
    "(2,'2019-02-01','2019-02-20',15),\n",
    "(2,'2019-02-21','2019-03-31',30)\n",
    "]\n",
    "prices_schema = ['product_id','start_date','end_date','price']\n",
    "\n",
    "unitssold = [\n",
    "(1,'2019-02-25',100),\n",
    "(1,'2019-03-01',15 ),\n",
    "(2,'2019-02-10',200),\n",
    "(2,'2019-03-22',30 )\n",
    "]\n",
    "unitssold_schema = ['product_id','purchase_date','units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1053cd85-61a0-4db7-89f7-ba28ea2b4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prices = spark.createDataFrame(data=prices,schema=prices_schema)\n",
    "df_unitssold = spark.createDataFrame(data=unitssold,schema=unitssold_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5b6215a-a0b0-4b3e-8722-6c0d3941aa79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|product_id|average_price|\n",
      "+----------+-------------+\n",
      "|         1|         6.96|\n",
      "|         2|        16.96|\n",
      "+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_prices.alias(\"p\").join( df_unitssold.alias(\"u\"), \n",
    "                           F.col(\"p.product_id\") == F.col(\"u.product_id\"),\n",
    "                           \"inner\"\n",
    "                         )\\\n",
    "    .where((F.col(\"u.purchase_date\") >= F.col(\"p.start_date\")) & (F.col(\"u.purchase_date\") <= F.col(\"p.end_date\")))\\\n",
    "    .groupBy(F.col(\"u.product_id\"))\\\n",
    "    .agg( F.round(F.sum(F.col(\"p.price\") * F.col(\"u.units\")) / F.sum(F.col(\"u.units\")),2).alias(\"average_price\") )\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63eb99b-fb42-4155-aa9d-3bcbfa5f695d",
   "metadata": {},
   "source": [
    "## SQL Solution \n",
    "\n",
    "<pre>\n",
    "    SELECT u.product_id, ROUND( SUM(p.price * u.units)/SUM(u.units), 2) \n",
    "    FROM Prices p \n",
    "    LEFT JOIN UnitsSold u ON p.product_id = u.product_id\n",
    "    WHERE u.purchase_date BETWEEN p.start_date AND p.end_date\n",
    "    GROUP BY u.product_id\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b5d46-e82c-4b4f-ac45-48f3d08ef046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
