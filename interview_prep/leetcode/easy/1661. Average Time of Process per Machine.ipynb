{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f00c698f-0027-4d88-b06c-7f82b6edc657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/07/25 01:20:35 WARN Utils: Your hostname, de24, resolves to a loopback address: 127.0.1.1; using 192.168.0.102 instead (on interface enp0s3)\n",
      "25/07/25 01:20:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/25 01:20:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.102:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>learning</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ea14f30b200>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "# Create a SparkConf object\n",
    "conf = SparkConf().setAppName(\"learning\")\\\n",
    "            .setMaster(\"local[4]\")\\\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35074b03-c1a9-433f-b49b-7521008d5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Table: Activity\n",
    "\n",
    "+----------------+---------+\n",
    "| Column Name    | Type    |\n",
    "+----------------+---------+\n",
    "| machine_id     | int     |\n",
    "| process_id     | int     |\n",
    "| activity_type  | enum    |\n",
    "| timestamp      | float   |\n",
    "+----------------+---------+\n",
    "The table shows the user activities for a factory website.\n",
    "(machine_id, process_id, activity_type) is the primary key (combination of columns with unique values) of \n",
    "this table.\n",
    "machine_id is the ID of a machine.\n",
    "process_id is the ID of a process running on the machine with ID machine_id.\n",
    "activity_type is an ENUM (category) of type ('start', 'end').\n",
    "timestamp is a float representing the current time in seconds.\n",
    "'start' means the machine starts the process at the given timestamp and 'end' means the machine ends the process \n",
    "at the given \n",
    "timestamp.\n",
    "The 'start' timestamp will always be before the 'end' timestamp for every (machine_id, process_id) pair.\n",
    " \n",
    "\n",
    "There is a factory website that has several machines each running the same number of processes. Write a solution \n",
    "to find the \n",
    "average time each machine takes to complete a process.\n",
    "\n",
    "The time to complete a process is the 'end' timestamp minus the 'start' timestamp. The average time is calculated \n",
    "by the total \n",
    "time to complete every process on the machine divided by the number of processes that were run.\n",
    "\n",
    "The resulting table should have the machine_id along with the average time as processing_time, which should \n",
    "be rounded to 3 \n",
    "decimal places.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Activity table:\n",
    "+------------+------------+---------------+-----------+\n",
    "| machine_id | process_id | activity_type | timestamp |\n",
    "+------------+------------+---------------+-----------+\n",
    "| 0          | 0          | start         | 0.712     |\n",
    "| 0          | 0          | end           | 1.520     |\n",
    "| 0          | 1          | start         | 3.140     |\n",
    "| 0          | 1          | end           | 4.120     |\n",
    "| 1          | 0          | start         | 0.550     |\n",
    "| 1          | 0          | end           | 1.550     |\n",
    "| 1          | 1          | start         | 0.430     |\n",
    "| 1          | 1          | end           | 1.420     |\n",
    "| 2          | 0          | start         | 4.100     |\n",
    "| 2          | 0          | end           | 4.512     |\n",
    "| 2          | 1          | start         | 2.500     |\n",
    "| 2          | 1          | end           | 5.000     |\n",
    "+------------+------------+---------------+-----------+\n",
    "Output: \n",
    "+------------+-----------------+\n",
    "| machine_id | processing_time |\n",
    "+------------+-----------------+\n",
    "| 0          | 0.894           |\n",
    "| 1          | 0.995           |\n",
    "| 2          | 1.456           |\n",
    "+------------+-----------------+\n",
    "Explanation: \n",
    "There are 3 machines running 2 processes each.\n",
    "Machine 0's average time is ((1.520 - 0.712) + (4.120 - 3.140)) / 2 = 0.894\n",
    "Machine 1's average time is ((1.550 - 0.550) + (1.420 - 0.430)) / 2 = 0.995\n",
    "Machine 2's average time is ((4.512 - 4.100) + (5.000 - 2.500)) / 2 = 1.456\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b569528-da6e-4169-9051-da30a725bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "(0,0,'start',0.712),\n",
    "(0,0,'end'  ,1.520),\n",
    "(0,1,'start',3.140),\n",
    "(0,1,'end'  ,4.120),\n",
    "(1,0,'start',0.550),\n",
    "(1,0,'end'  ,1.550),\n",
    "(1,1,'start',0.430),\n",
    "(1,1,'end'  ,1.420),\n",
    "(2,0,'start',4.100),\n",
    "(2,0,'end'  ,4.512),\n",
    "(2,1,'start',2.500),\n",
    "(2,1,'end'  ,5.000)\n",
    "]\n",
    "schema = ['machine_id','process_id','activity_type','timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c21dcce-ea09-4ecf-b47b-fef39e53d811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------+---------+\n",
      "|machine_id|process_id|activity_type|timestamp|\n",
      "+----------+----------+-------------+---------+\n",
      "|         0|         0|        start|    0.712|\n",
      "|         0|         0|          end|     1.52|\n",
      "|         0|         1|        start|     3.14|\n",
      "|         0|         1|          end|     4.12|\n",
      "|         1|         0|        start|     0.55|\n",
      "|         1|         0|          end|     1.55|\n",
      "|         1|         1|        start|     0.43|\n",
      "|         1|         1|          end|     1.42|\n",
      "|         2|         0|        start|      4.1|\n",
      "|         2|         0|          end|    4.512|\n",
      "|         2|         1|        start|      2.5|\n",
      "|         2|         1|          end|      5.0|\n",
      "+----------+----------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data = data, schema = schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bdb37c5-56a8-4171-a07d-77acc5fe378f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+------------------+\n",
      "|machine_id|process_id|        difference|\n",
      "+----------+----------+------------------+\n",
      "|         0|         1|              0.98|\n",
      "|         0|         0|             0.808|\n",
      "|         1|         0|               1.0|\n",
      "|         1|         1|              0.99|\n",
      "|         2|         0|0.4119999999999999|\n",
      "|         2|         1|               2.5|\n",
      "+----------+----------+------------------+\n",
      "\n",
      "+----------+---------------+\n",
      "|machine_id|processing_time|\n",
      "+----------+---------------+\n",
      "|0         |0.894          |\n",
      "|1         |0.995          |\n",
      "|2         |1.456          |\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_tmp = df.groupBy(F.col(\"machine_id\"),F.col(\"process_id\"))\\\n",
    "            .agg((F.max(F.col(\"timestamp\")) - F.min(F.col(\"timestamp\"))).alias(\"difference\"))\n",
    "\n",
    "df_tmp.show()\n",
    "\n",
    "df_tmp.groupBy(F.col(\"machine_id\"))\\\n",
    "      .agg(F.round(F.avg(F.col(\"difference\")),3).alias(\"processing_time\"))\\\n",
    "      .show(truncate=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c98ab50-0aa8-4cf3-9960-badd6a05c99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|machine_id|processing_time|\n",
      "+----------+---------------+\n",
      "|0         |0.894          |\n",
      "|1         |0.995          |\n",
      "|2         |1.456          |\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3 same as above query but combining\n",
    "df.groupBy(F.col(\"machine_id\"),F.col(\"process_id\"))\\\n",
    "            .agg((F.max(F.col(\"timestamp\")) - F.min(F.col(\"timestamp\"))).alias(\"difference\"))\\\n",
    ".groupBy(F.col(\"machine_id\"))\\\n",
    "      .agg(F.round(F.avg(F.col(\"difference\")),3).alias(\"processing_time\"))\\\n",
    "      .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b9e9a7-ff83-4910-9d15-d706d160455c",
   "metadata": {},
   "source": [
    "## Anothor Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52e5b345-79ec-40bc-a3a0-fc417006ce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|machine_id|processing_time|\n",
      "+----------+---------------+\n",
      "|0         |0.894          |\n",
      "|1         |0.995          |\n",
      "|2         |1.456          |\n",
      "+----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.alias(\"s\").join(df.alias(\"e\"), \n",
    "                   (F.col(\"s.machine_id\") == F.col(\"e.machine_id\")) & (F.col(\"s.process_id\") == F.col(\"e.process_id\")),\n",
    "                  'left')\\\n",
    "             .where((F.col(\"s.activity_type\") == 'start') & (F.col(\"e.activity_type\") == 'end'))\\\n",
    "             .groupBy(F.col(\"s.machine_id\"))\\\n",
    "             .agg(F.round(F.avg(F.col(\"e.timestamp\")-F.col(\"s.timestamp\")),3).alias(\"processing_time\"))\\\n",
    "             .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df836f2-0583-4224-a267-80c579fbec2b",
   "metadata": {},
   "source": [
    "## SQL Solution\n",
    "\n",
    "<pre>\n",
    "    WITH TEMP AS (\n",
    "        SELECT machine_id, process_id, MAX(timestamp)-MIN(timestamp) as difference\n",
    "        FROM Activity \n",
    "        GROUP BY machine_id, process_id\n",
    "    )\n",
    "    SELECT machine_id, AVG(difference)\n",
    "    FROM TEMP\n",
    "    GROUP BY TEMP;\n",
    "</pre>\n",
    "\n",
    "## Anothor Approach\n",
    "\n",
    "<pre>\n",
    "SELECT s.machine_id, ROUND(AVG(e.timestamp-s.timestamp), 3) AS processing_time\n",
    "FROM Activity s JOIN Activity e ON s.machine_id = e.machine_id \n",
    "                AND s.process_id = e.process_id \n",
    "                AND s.activity_type = 'start' \n",
    "                AND e.activity_type = 'end'\n",
    "    GROUP BY s.machine_id;\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35e7a48-25af-47e8-b69b-e8eb43bc7563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
