{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896b73fe-b6c6-485b-83b3-411add8eacbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/07/29 01:19:55 WARN Utils: Your hostname, de24, resolves to a loopback address: 127.0.1.1; using 192.168.0.102 instead (on interface enp0s3)\n",
      "25/07/29 01:19:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/29 01:19:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.102:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>1667</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7bce4345d6d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark \n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "conf = SparkConf().setAppName(\"1667\").setMaster(\"local[4]\")\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e0b536-86e8-4ed6-8ece-a15fbd78f961",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Table: Users\n",
    "\n",
    "+----------------+---------+\n",
    "| Column Name    | Type    |\n",
    "+----------------+---------+\n",
    "| user_id        | int     |\n",
    "| name           | varchar |\n",
    "+----------------+---------+\n",
    "user_id is the primary key (column with unique values) for this table.\n",
    "This table contains the ID and the name of the user. \n",
    "The name consists of only lowercase and uppercase characters.\n",
    " \n",
    "\n",
    "Write a solution to fix the names so that only the first character \n",
    "is uppercase and the rest are lowercase.\n",
    "\n",
    "Return the result table ordered by user_id.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Users table:\n",
    "+---------+-------+\n",
    "| user_id | name  |\n",
    "+---------+-------+\n",
    "| 1       | aLice |\n",
    "| 2       | bOB   |\n",
    "+---------+-------+\n",
    "Output: \n",
    "+---------+-------+\n",
    "| user_id | name  |\n",
    "+---------+-------+\n",
    "| 1       | Alice |\n",
    "| 2       | Bob   |\n",
    "+---------+-------+\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e19766a-6c48-4ee4-ad58-632db5d81420",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "(1,'aLice'),\n",
    "(2,'bOB'  )\n",
    "]\n",
    "schema = ['user_id','name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3086c5b9-dbed-498a-a36e-be10aea40b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|user_id| name|\n",
      "+-------+-----+\n",
      "|      1|aLice|\n",
      "|      2|  bOB|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data=data,schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ab10ac3-9cc2-4a25-b986-860fa164f70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|user_id| name|\n",
      "+-------+-----+\n",
      "|      1|Alice|\n",
      "|      2|  Bob|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.col(\"user_id\"), \n",
    "          F.concat(\n",
    "            F.upper(F.substring(F.col(\"name\"),1,1)),\n",
    "            F.lower(F.substring(F.col(\"name\"),2,F.length(F.col(\"name\"))))).alias(\"name\")\n",
    "                )\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c15ebc-210f-42bb-99f9-2a4def596a7d",
   "metadata": {},
   "source": [
    "## SQL Solution \n",
    "<pre>\n",
    "SELECT user_id, CONCAT(UPPER(SUBSTRING(name,0,1)),LOWER(SUBSTRING(name,1,LENGTH(name)))) as name\n",
    "FROM Users\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a784c6-70e4-4154-8e99-7e7821122fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
