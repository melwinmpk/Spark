{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59fc7592-5f9c-4a18-ba95-567581f5c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/07/30 00:59:17 WARN Utils: Your hostname, de24, resolves to a loopback address: 127.0.1.1; using 192.168.0.102 instead (on interface enp0s3)\n",
      "25/07/30 00:59:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/30 00:59:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.102:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v4.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>1789</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7bd5104d0380>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "conf = SparkConf().setAppName(\"1789\").setMaster(\"local[4]\")\n",
    "spark = SparkSession.builder.config(conf = conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392f99a-7797-44d9-aa64-eadb9f725fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Table: Employee\n",
    "\n",
    "+---------------+---------+\n",
    "| Column Name   |  Type   |\n",
    "+---------------+---------+\n",
    "| employee_id   | int     |\n",
    "| department_id | int     |\n",
    "| primary_flag  | varchar |\n",
    "+---------------+---------+\n",
    "(employee_id, department_id) is the primary key \n",
    "(combination of columns with unique values) for this table.\n",
    "employee_id is the id of the employee.\n",
    "department_id is the id of the department to which the employee belongs.\n",
    "primary_flag is an ENUM (category) of type ('Y', 'N'). If the flag is 'Y', \n",
    "the department is the primary department for the employee. If the flag is 'N', \n",
    "the department is not the primary.\n",
    " \n",
    "\n",
    "Employees can belong to multiple departments. When the employee joins other departments, \n",
    "they need to decide which department is their primary department. \n",
    "Note that when an employee belongs to only one department, their primary column is 'N'.\n",
    "\n",
    "Write a solution to report all the employees with their primary department. \n",
    "For employees who belong to one department, report their only department.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Employee table:\n",
    "+-------------+---------------+--------------+\n",
    "| employee_id | department_id | primary_flag |\n",
    "+-------------+---------------+--------------+\n",
    "| 1           | 1             | N            |\n",
    "| 2           | 1             | Y            |\n",
    "| 2           | 2             | N            |\n",
    "| 3           | 3             | N            |\n",
    "| 4           | 2             | N            |\n",
    "| 4           | 3             | Y            |\n",
    "| 4           | 4             | N            |\n",
    "+-------------+---------------+--------------+\n",
    "Output: \n",
    "+-------------+---------------+\n",
    "| employee_id | department_id |\n",
    "+-------------+---------------+\n",
    "| 1           | 1             |\n",
    "| 2           | 1             |\n",
    "| 3           | 3             |\n",
    "| 4           | 3             |\n",
    "+-------------+---------------+\n",
    "Explanation: \n",
    "- The Primary department for employee 1 is 1.\n",
    "- The Primary department for employee 2 is 1.\n",
    "- The Primary department for employee 3 is 3.\n",
    "- The Primary department for employee 4 is 3.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef75eb1b-73b1-45be-ac44-158e57e6d78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "(1,1,'N'),\n",
    "(2,1,'Y'),\n",
    "(2,2,'N'),\n",
    "(3,3,'N'),\n",
    "(4,2,'N'),\n",
    "(4,3,'Y'),\n",
    "(4,4,'N')    \n",
    "]\n",
    "schema = ['employee_id','department_id','primary_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1afde184-9707-47ce-ace2-18857eac8d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------------+\n",
      "|employee_id|department_id|primary_flag|\n",
      "+-----------+-------------+------------+\n",
      "|          1|            1|           N|\n",
      "|          2|            1|           Y|\n",
      "|          2|            2|           N|\n",
      "|          3|            3|           N|\n",
      "|          4|            2|           N|\n",
      "|          4|            3|           Y|\n",
      "|          4|            4|           N|\n",
      "+-----------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(data=data, schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c49cfe65-b66b-4cc2-8884-5fc673502833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|employee_id|department_id|\n",
      "+-----------+-------------+\n",
      "|          2|            1|\n",
      "|          4|            3|\n",
      "|          1|            1|\n",
      "|          3|            1|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.col(\"employee_id\"),F.col(\"department_id\"))\\\n",
    "  .where(F.col(\"primary_flag\") == 'Y')\\\n",
    "  .union(\n",
    "      df.select(F.col(\"employee_id\"),F.col(\"department_id\"))\\\n",
    "        .groupBy(F.col(\"employee_id\"))\n",
    "        .agg(F.count(F.col(\"department_id\")).alias(\"count\"))\\\n",
    "        .where(F.col(\"count\") == 1)\n",
    "  )\\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b907020-47b9-4d92-8172-8dd2a7af9d39",
   "metadata": {},
   "source": [
    "## Wrong output \n",
    "\n",
    "in the Sql the solution is there however in pyspark Dataframe <br>\n",
    "Solution is really close,  that instinct to embed both logic paths in one chained statement is sharp. <br>ðŸš€ However, thereâ€™s one subtle catch: in the second half, after the groupBy, you're aggregating and filtering but still trying to select(\"employee_id\", \"department_id\") from that result. </b>The department_id column is lost during aggregation, so the union throws a mismatch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175f106e-78db-46ef-9ce9-67bb82281df1",
   "metadata": {},
   "source": [
    "## Correct Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34cdd686-cd49-4cc1-a725-61556e7dd6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|employee_id|department_id|\n",
      "+-----------+-------------+\n",
      "|          2|            1|\n",
      "|          4|            3|\n",
      "|          1|            1|\n",
      "|          3|            3|\n",
      "+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_flag = df.groupBy(F.col(\"employee_id\"))\\\n",
    "            .agg(F.count(F.col(\"*\")).alias(\"count\"))\\\n",
    "            .where(F.col(\"count\") == 1)\n",
    "\n",
    "df_single = df_flag.alias(\"e\").join(df.alias(\"e1\"), \n",
    "                               F.col(\"e.employee_id\") == F.col(\"e1.employee_id\"),\n",
    "                               'left')\\\n",
    "                         .select(F.col(\"e.employee_id\"), F.col(\"e1.department_id\"))\n",
    "\n",
    "df.select(F.col(\"employee_id\"),F.col(\"department_id\"))\\\n",
    "  .where(F.col(\"primary_flag\") == 'Y')\\\n",
    "  .union(\n",
    "      df_single.select(F.col(\"employee_id\"),F.col(\"department_id\"))\n",
    "  ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ddcf4f-61c2-4297-8dbd-196a93853d61",
   "metadata": {},
   "source": [
    "## SQL Solution\n",
    "\n",
    "<pre>\n",
    "\n",
    "SELECT employee_id, department_id \n",
    "FROM Employee \n",
    "WHERE primary_flag = 'Y'\n",
    "UNION \n",
    "SELECT employee_id, department_id \n",
    "FROM Employee \n",
    "GROUP BY employee_id\n",
    "HAVING count(department_id) = 1\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0beb91-762f-4828-98fe-d9e1d745d3f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
