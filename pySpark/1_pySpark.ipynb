{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba4a001",
   "metadata": {},
   "source": [
    "<h1>PySpark</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5283ffb8",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>PySpark is a Python API for Apache Spark to process larger datasets in a\n",
    "distributed cluster. <br>It is written in Python to run a Python application using\n",
    "Apache Spark capabilities</li>\n",
    "    <li>Spark basically is written in Scala, and due to its adaptation in industry, <br> its\n",
    "equivalent PySpark API has been released for Python Py4J. </li>\n",
    "    <li><b>Py4J</b> is a Java library that is integrated within Spark and allows python to\n",
    "dynamically interface with JVM objects, <br>hence to run PySpark you also need Java\n",
    "to be installed along with Python, and Apache Spark. </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92729d7",
   "metadata": {},
   "source": [
    "<h2>Features of Spark</h2>\n",
    "<ol>\n",
    "    <li>PySpark RDD (pyspark.RDD)</li>\n",
    "    <li>PySpark DataFrame and SQL (pyspark.sql)</li>\n",
    "    <li>PySpark Streaming (pyspark.streaming)</li>\n",
    "    <li>PySpark MLib (pyspark.ml, pyspark.mllib)</li>\n",
    "    <li>PySpark GraphFrames (GraphFrames)</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a0e9bd",
   "metadata": {},
   "source": [
    "<h3>How to create SparkContext using SparkConf ?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c836cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages that must be Imported\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create conf object\n",
    "# setAppNAme should be the relevent one based on the Program\n",
    "sparkConf = SparkConf ( ) \\\n",
    " .setAppName (\"WordCount\") \\\n",
    " .setMaster (“local”) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512b2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkContext object \n",
    "sc = SparkContext (conf=sparkConf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f779c101",
   "metadata": {},
   "source": [
    "Note: <b>Only one SparkContext</b> may be active per <b>JVM</b>. You must stop the active one before\n",
    "creating a new one as shown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b955b8e9",
   "metadata": {},
   "source": [
    "<h3>How to create SparkSession?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .appName(\"WordCount\")\\\n",
    "        .master(\"local[3]\")\\\n",
    "        .getOrCreate( )\n",
    "spark.sparkContext ( ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3155df09",
   "metadata": {},
   "source": [
    "<h3>what is the setMaster in SparkContext and SparkSession Code?</h3>\n",
    "<p><b>setMaster(String master)</b> The master URL to connect to,<br> \n",
    "      such as \"local\" to run locally with one thread,<br> \"local[4]\" to run locally with 4 cores,<br>\n",
    "    or \"spark://master:7077\" to run on a Spark standalone cluster.<br> SparkConf. setSparkHome(String home) Set the location where Spark is installed on worker nodes.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932834bb",
   "metadata": {},
   "source": [
    "<h3>What does getOrCreate do in Spark?</h3>\n",
    "<p>Within the same JVM, getOrCreate() will give you the same instance of SparkContext;<br>\n",
    "   and this will help you share broadcast variables,<br> \n",
    "   etc among different applications spawned by the same Spark Driver.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e5679f",
   "metadata": {},
   "source": [
    "<h3>Read data from text file</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272b990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "readFile = sc.textFile(\"hdfs://localhost:9000/user/saif/HFS/Input/wordcount.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
