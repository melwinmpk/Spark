{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893f39a1",
   "metadata": {},
   "source": [
    "##  Explode Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96312b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66f30175",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark  =  SparkSession.builder.appName('yettodecide').master('local').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "440df699",
   "metadata": {},
   "outputs": [],
   "source": [
    "explodeData = [('Saif', ['Java', 'Scala'], {'hair': 'black', 'eye': 'brown'}),\n",
    " ('Mitali', ['Spark', 'Java', None], {'hair': 'brown', 'eye': None}),\n",
    " ('Ram', ['CSharp', ''], {'hair': 'red', 'eye': ''}),\n",
    " ('Wilma', None, None)\n",
    "#  ,('Jatin', ['1', '2'], {})\n",
    "              ]\n",
    "array_df = spark.createDataFrame(data=explodeData,\n",
    "schema=['name', 'knownLanguages', 'properties']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fafb585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+-----------------------------+\n",
      "|name  |knownLanguages|properties                   |\n",
      "+------+--------------+-----------------------------+\n",
      "|Saif  |[Java, Scala] |[eye -> brown, hair -> black]|\n",
      "|Mitali|[Spark, Java,]|[eye ->, hair -> brown]      |\n",
      "|Ram   |[CSharp, ]    |[eye -> , hair -> red]       |\n",
      "|Wilma |null          |null                         |\n",
      "+------+--------------+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "array_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e68763eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- knownLanguages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "+------+--------------+--------------------+------+\n",
      "|  name|knownLanguages|          properties|  name|\n",
      "+------+--------------+--------------------+------+\n",
      "|  Saif| [Java, Scala]|[eye -> brown, ha...|  Java|\n",
      "|  Saif| [Java, Scala]|[eye -> brown, ha...| Scala|\n",
      "|Mitali|[Spark, Java,]|[eye ->, hair -> ...| Spark|\n",
      "|Mitali|[Spark, Java,]|[eye ->, hair -> ...|  Java|\n",
      "|Mitali|[Spark, Java,]|[eye ->, hair -> ...|  null|\n",
      "|   Ram|    [CSharp, ]|[eye -> , hair ->...|CSharp|\n",
      "|   Ram|    [CSharp, ]|[eye -> , hair ->...|      |\n",
      "+------+--------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode,col\n",
    "# explode\n",
    "df2 = array_df.select(col(\"*\"), explode(\"knownLanguages\").alias('name'))\n",
    "df2.printSchema()\n",
    "df2.show() "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d085432",
   "metadata": {},
   "source": [
    "Note:\n",
    "This will ignore elements that have null or empty.\n",
    "Wilma and Jatin have null or empty values in array and map hence the following\n",
    "snippet does not contain these rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b15f75d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- key: string (nullable = false)\n",
      " |-- value: string (nullable = true)\n",
      "\n",
      "+------+----+-----+\n",
      "|  name| key|value|\n",
      "+------+----+-----+\n",
      "|  Saif| eye|brown|\n",
      "|  Saif|hair|black|\n",
      "|Mitali| eye| null|\n",
      "|Mitali|hair|brown|\n",
      "|   Ram| eye|     |\n",
      "|   Ram|hair|  red|\n",
      "+------+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explode map\n",
    "df3 = array_df.select(array_df.name, explode(array_df.properties))\n",
    "df3.printSchema()\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0659df",
   "metadata": {},
   "source": [
    "https://sparkbyexamples.com/pyspark/pyspark-explode-array-and-map-columns-to-rows/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d86e7db",
   "metadata": {},
   "source": [
    "## Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f58410ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superior_emp_id: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- emp_dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|    name|superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|     1|   Smith|             -1|       2018|         10|     M|  3000|\n",
      "|     2|    Rose|              1|       2010|         20|     M|  4000|\n",
      "|     3|Williams|              1|       2010|         10|     M|  1000|\n",
      "|     4|   Jones|              2|       2005|         10|     F|  2000|\n",
      "|     5|   Brown|              2|       2010|         40|      |    -1|\n",
      "|     6|   Brown|              2|       2010|         50|      |    -1|\n",
      "|    50|     Bob|              2|       2010|         50|      |    -1|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n",
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|  Finance|     10|\n",
      "|Marketing|     20|\n",
      "|    Sales|     30|\n",
      "|       IT|     40|\n",
      "|      R&D|    101|\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000), \\\n",
    "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000), \\\n",
    "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000), \\\n",
    "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000), \\\n",
    "    (5,\"Brown\",2,\"2010\",\"40\",\"\",-1), \\\n",
    "      (6,\"Brown\",2,\"2010\",\"50\",\"\",-1), \\\n",
    "       (50,\"Bob\",2,\"2010\",\"50\",\"\",-1)\n",
    "  ]\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\", \\\n",
    "       \"emp_dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
    "empDF.printSchema()\n",
    "empDF.show()\n",
    "\n",
    "dept = [(\"Finance\",10), \\\n",
    "    (\"Marketing\",20), \\\n",
    "    (\"Sales\",30), \\\n",
    "    (\"IT\",40), \\\n",
    "    (\"R&D\",101)    \n",
    "  ]\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "deptDF.printSchema()\n",
    "deptDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8f6277",
   "metadata": {},
   "source": [
    "### Inner Join\n",
    "Inner join is the default join in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9925bc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"inner\").show(truncate=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7885a4d",
   "metadata": {},
   "source": [
    "### Full Outer Join\n",
    "fullouter join returns all rows from both datasets where join\n",
    "expression doesnâ€™t match it returns null on respective record columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb832c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n",
      "|50    |Bob     |2              |2010       |50         |      |-1    |null     |null   |\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|null  |null    |null           |null       |null       |null  |null  |R&D      |101    |\n",
      "|null  |null    |null           |null       |null       |null  |null  |Sales    |30     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"outer\").show(truncate=False) \n",
    "# OR\n",
    "# empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"full\").show(truncate=False) \n",
    "# OR \n",
    "# empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"fullouter\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3c10f",
   "metadata": {},
   "source": [
    "### Left Outer Join\n",
    "Leftouter join returns all rows from the left dataset regardless of match\n",
    "found on the right dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8bf1cb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |null     |null   |\n",
      "|50    |Bob     |2              |2010       |50         |      |-1    |null     |null   |\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"left\").show(truncate=False)\n",
    "# OR\n",
    "# empDF.join(deptDF, empDF(\"emp_dept_id\") == deptDF(\"dept_id\"), \"leftouter\").show(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59157883",
   "metadata": {},
   "source": [
    "###  Right Outer Join\n",
    "a Rightouter join is opposite of left join, here it returns all rows from the\n",
    "right dataset regardless of match found on the left dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6b2532c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|null  |null    |null           |null       |null       |null  |null  |R&D      |101    |\n",
      "|null  |null    |null           |null       |null       |null  |null  |Sales    |30     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"right\").show(truncate=False) \n",
    "# OR\n",
    "# empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"rightouter\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481fad4",
   "metadata": {},
   "source": [
    "###  Left Semi Join\n",
    "<ul>\n",
    "<li>leftsemi join is similar to inner join difference being leftsemi join returns all columns from the left dataset and ignores all columns from the right dataset </li>\n",
    "<li>In other words, this join returns columns from the only left dataset for the records\n",
    "match in the right dataset on join expression records not matched on join\n",
    "expression are ignored from both left and right datasets.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d6dd63e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"leftsemi\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fd2463",
   "metadata": {},
   "source": [
    "### Left Anti Join\n",
    "<ul>\n",
    "<li>leftanti join does the exact opposite of the leftsemi.</li>\n",
    "<li>leftanti join returns only columns from the left dataset for non-matched records. </li>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "382eb6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "|6     |Brown|2              |2010       |50         |      |-1    |\n",
      "|50    |Bob  |2              |2010       |50         |      |-1    |\n",
      "+------+-----+---------------+-----------+-----------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF, empDF.emp_dept_id == deptDF.dept_id, \"leftanti\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb572b3",
   "metadata": {},
   "source": [
    "### Self Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d5c81f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------------+\n",
      "|emp_id|name    |superior_emp_id|superior_emp_name|\n",
      "+------+--------+---------------+-----------------+\n",
      "|2     |Rose    |1              |Smith            |\n",
      "|3     |Williams|1              |Smith            |\n",
      "|4     |Jones   |2              |Rose             |\n",
      "|5     |Brown   |2              |Rose             |\n",
      "|6     |Brown   |2              |Rose             |\n",
      "|50    |Bob     |2              |Rose             |\n",
      "+------+--------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.alias(\"emp1\").join(empDF.alias(\"emp2\"),\n",
    " col(\"emp1.superior_emp_id\") == col(\"emp2.emp_id\"), \"inner\") \\\n",
    " .select(col(\"emp1.emp_id\"), col(\"emp1.name\"), \\\n",
    " col(\"emp2.emp_id\").alias(\"superior_emp_id\"), \\\n",
    " col(\"emp2.name\").alias(\"superior_emp_name\")) \\\n",
    " .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdd4bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
